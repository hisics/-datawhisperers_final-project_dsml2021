{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "datawhisperers_sentiment_analysis_amazon_apparel_reviews.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3WLtzXUTC5LN",
        "UlcIQtgryy47"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.4 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
        }
      },
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4-final"
    },
    "orig_nbformat": 2
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hisics/-datawhisperers_final-project_dsml2021/blob/heba/datawhisperers_sentiment_analysis_amazon_apparel_reviews.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub7F7w29_l0Z"
      },
      "source": [
        "# <b>Capstone Project - ML on Apparel Reviews at Amazon US\n",
        "The Data Whisperers Team ✨  Amba | Bhavya | Sushma | Heba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WLtzXUTC5LN"
      },
      "source": [
        "#### Chosen project : Option 8 - Sentiment Analysis for Ecommerce | Apparel\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCbIE2LUglbI"
      },
      "source": [
        "<b>Objectives</b>\n",
        "- Product owner's perspective: \n",
        "  - Quality improvement |\n",
        "  - Gap analysis | same product different maker?\n",
        "  - Reputation management\n",
        "- Investor's perspective: \n",
        "  - which product owners improve over time\n",
        "- Consumer perspective\n",
        "  - Influencial posts\n",
        "\n",
        "- ML Practice | Inferrential analysis for positive or negative feedback on products in social media product  \n",
        "\n",
        "\n",
        "---\n",
        "Notes: \n",
        "* #todo : means to check or come back to the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeWDiw-r98hn"
      },
      "source": [
        "<b>Understanding the Dataset</b>\n",
        "\n",
        "* marketplace       : 2 letter country code of the marketplace where the review was written.\n",
        "*customer_id       : Random identifier that can be used to aggregate *reviews written by a single author.\n",
        "*review_id         : The unique ID of the review.\n",
        "*product_id        : The unique Product ID the review pertains to. In the multilingual dataset the reviews for the same product in different countries can be grouped by the same product_id.\n",
        "*product_parent    : Random identifier that can be used to aggregatereviews for the same product.\n",
        "*product_title     : Title of the product.\n",
        "*product_category  : Broad product category that can be used to group reviews  (also used to group the dataset into coherent parts).\n",
        "*star_rating       : The 1-5 star rating of the review.\n",
        "*helpful_votes     : Number of helpful votes.\n",
        "*total_votes       : Number of total votes the review received.\n",
        "*vine              : Review was written as part of the Vine program.\n",
        "*verified_purchase : The review is on a verified purchase.\n",
        "*review_headline   : The title of the review.\n",
        "*review_body       : The review text.\n",
        "*review_date       : The date the review was written.\n",
        "\n",
        "From Dany: Look at this document for reference,<br/>\n",
        "https://colab.research.google.com/drive/1g6ZtYOOhGUj1WsiPpeaVPp5T7VFw234e?usp=sharing\n",
        "\n",
        "https://www.tensorflow.org/datasets/catalog/amazon_us_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgCQXJ3G_b9K"
      },
      "source": [
        "#### Importing libaries and Apparel dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7TFp0sC5LV"
      },
      "source": [
        "# (1) Import libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBaD7dvAC5LW",
        "outputId": "5c16f3a4-ec9f-4685-823a-5d133b0eaedf"
      },
      "source": [
        "# (2) Download product reviews from Amazon Datasets\n",
        "# You can use reviews from Amazon Datasets for a particular product.\n",
        "# Note that the data are quite large so do not run this cell unless you are willing to wait!\n",
        "# For reference, visit:\n",
        "# https://www.tensorflow.org/datasets/catalog/amazon_us_reviews\n",
        "# https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
        "!curl -O https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Apparel_v1_00.tsv.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  618M  100  618M    0     0  62.1M      0  0:00:09  0:00:09 --:--:-- 61.8M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG7i-4E7DR6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50992613-4f55-47d0-ae26-d222e83ec97e"
      },
      "source": [
        "!echo \"y\" | gzip -d amazon_reviews_us_Apparel_v1_00.tsv.gz"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: amazon_reviews_us_Apparel_v1_00.tsv already exists;\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7MGo9e-C5LX",
        "outputId": "75517d74-3718-4529-cf32-f31ccec1f6f8"
      },
      "source": [
        "# (3.a) Read the contents of the folder \n",
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amazon_reviews_us_Apparel_v1_00.tsv\tapparelReviewsDataset_300k.csv\n",
            "amazon_reviews_us_Apparel_v1_00.tsv.gz\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPwqyKTuC5LX"
      },
      "source": [
        "# (3.b) Explore data (see what is categorial and numerical)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lytjIOzXD2Zu",
        "outputId": "6bf2bbc1-1636-49b6-e5e2-9b6457058f2c"
      },
      "source": [
        "df = pd.read_table('amazon_reviews_us_Apparel_v1_00.tsv', delim_whitespace=False, error_bad_lines=False, nrows=300000)\n",
        "df.info()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "b'Skipping line 49396: expected 15 fields, saw 22\\nSkipping line 57008: expected 15 fields, saw 22\\n'\n",
            "b'Skipping line 82075: expected 15 fields, saw 22\\nSkipping line 104435: expected 15 fields, saw 22\\nSkipping line 109766: expected 15 fields, saw 22\\nSkipping line 124024: expected 15 fields, saw 22\\nSkipping line 129914: expected 15 fields, saw 22\\nSkipping line 130172: expected 15 fields, saw 22\\n'\n",
            "b'Skipping line 161515: expected 15 fields, saw 22\\n'\n",
            "b'Skipping line 230464: expected 15 fields, saw 22\\n'\n",
            "b'Skipping line 292640: expected 15 fields, saw 22\\nSkipping line 293681: expected 15 fields, saw 22\\n'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300000 entries, 0 to 299999\n",
            "Data columns (total 15 columns):\n",
            " #   Column             Non-Null Count   Dtype \n",
            "---  ------             --------------   ----- \n",
            " 0   marketplace        300000 non-null  object\n",
            " 1   customer_id        300000 non-null  int64 \n",
            " 2   review_id          300000 non-null  object\n",
            " 3   product_id         300000 non-null  object\n",
            " 4   product_parent     300000 non-null  int64 \n",
            " 5   product_title      300000 non-null  object\n",
            " 6   product_category   300000 non-null  object\n",
            " 7   star_rating        300000 non-null  int64 \n",
            " 8   helpful_votes      300000 non-null  int64 \n",
            " 9   total_votes        300000 non-null  int64 \n",
            " 10  vine               300000 non-null  object\n",
            " 11  verified_purchase  300000 non-null  object\n",
            " 12  review_headline    299999 non-null  object\n",
            " 13  review_body        299858 non-null  object\n",
            " 14  review_date        299997 non-null  object\n",
            "dtypes: int64(5), object(10)\n",
            "memory usage: 34.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "glfGT55PxCuu",
        "outputId": "2730cafd-4caa-4dc3-9fba-8725818e8c73"
      },
      "source": [
        "# To see how the data looks like and if any is boolean\n",
        "df.tail()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>marketplace</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_parent</th>\n",
              "      <th>product_title</th>\n",
              "      <th>product_category</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>helpful_votes</th>\n",
              "      <th>total_votes</th>\n",
              "      <th>vine</th>\n",
              "      <th>verified_purchase</th>\n",
              "      <th>review_headline</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>299995</th>\n",
              "      <td>US</td>\n",
              "      <td>11794308</td>\n",
              "      <td>RGL12VWDODBGF</td>\n",
              "      <td>B00RNT944O</td>\n",
              "      <td>885862037</td>\n",
              "      <td>Dagacci Medical Uniform Women's Scrub Set Stre...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>They would be a decent pair of scrubs for the ...</td>\n",
              "      <td>They would be a decent pair of scrubs for the ...</td>\n",
              "      <td>2015-08-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299996</th>\n",
              "      <td>US</td>\n",
              "      <td>10525470</td>\n",
              "      <td>R1D9YUDSAF43Z9</td>\n",
              "      <td>B00RNT944O</td>\n",
              "      <td>885862037</td>\n",
              "      <td>Dagacci Medical Uniform Women's Scrub Set Stre...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Fit?</td>\n",
              "      <td>I want to start by saying I love the style. Th...</td>\n",
              "      <td>2015-06-08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299997</th>\n",
              "      <td>US</td>\n",
              "      <td>11785074</td>\n",
              "      <td>R38HJNAO7LK722</td>\n",
              "      <td>B00RNT944O</td>\n",
              "      <td>885862037</td>\n",
              "      <td>Dagacci Medical Uniform Women's Scrub Set Stre...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>One Star</td>\n",
              "      <td>They were too small, and it was difficult to r...</td>\n",
              "      <td>2015-05-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299998</th>\n",
              "      <td>US</td>\n",
              "      <td>24098870</td>\n",
              "      <td>R3TT5VMKGA7MG6</td>\n",
              "      <td>B00RNT944O</td>\n",
              "      <td>885862037</td>\n",
              "      <td>Dagacci Medical Uniform Women's Scrub Set Stre...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>For the price these scrubs are great! The top ...</td>\n",
              "      <td>For the price these scrubs are great! The top ...</td>\n",
              "      <td>2015-08-31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299999</th>\n",
              "      <td>US</td>\n",
              "      <td>19988435</td>\n",
              "      <td>R1V5G2V0O5QXDT</td>\n",
              "      <td>B00RNT940S</td>\n",
              "      <td>885862037</td>\n",
              "      <td>Dagacci Medical Uniform Women's Scrub Set Stre...</td>\n",
              "      <td>Apparel</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>Y</td>\n",
              "      <td>Three Stars</td>\n",
              "      <td>good quality but it's quite large for me</td>\n",
              "      <td>2015-08-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       marketplace  ...  review_date\n",
              "299995          US  ...   2015-08-02\n",
              "299996          US  ...   2015-06-08\n",
              "299997          US  ...   2015-05-12\n",
              "299998          US  ...   2015-08-31\n",
              "299999          US  ...   2015-08-26\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkCf5Pk9YCx"
      },
      "source": [
        "###Cleaning data and converting data types\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IKKlScwO-yZ"
      },
      "source": [
        "#### Pre-processing the columns without review text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-2JEGQ9ymK3",
        "outputId": "be80a299-daea-48ba-9da0-112425162a8b"
      },
      "source": [
        "# Checking unique values of each row in all columns\n",
        "n = df.nunique(axis=0)\n",
        "print(\n",
        "    \"Total number of rows in this data set is:{}\\nNumber of unique values in each column for in this dataset is:\\n\"\n",
        "    .format(len(df)), n)\n",
        "# outcome --> drop marketplace-category-reviewID\n",
        "# outcome --> bool vine verified purchase"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of rows in this data set is:300000\n",
            "Number of unique values in each column for in this dataset is:\n",
            " marketplace               1\n",
            "customer_id          241149\n",
            "review_id            300000\n",
            "product_id           182913\n",
            "product_parent       103541\n",
            "product_title        100013\n",
            "product_category          1\n",
            "star_rating               5\n",
            "helpful_votes           277\n",
            "total_votes             293\n",
            "vine                      2\n",
            "verified_purchase         2\n",
            "review_headline      143469\n",
            "review_body          270057\n",
            "review_date             271\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSPAMKIX2rdt",
        "outputId": "3e1a53d8-640f-4846-ed6e-a73607d87210"
      },
      "source": [
        "# # creating numerical df -> df_num\n",
        "# # creating categorical df -> df_cat\n",
        "cat_list = ['marketplace','review_id','product_id','product_title','product_category','vine','verified_purchase','review_headline','review_body','review_date']\n",
        "\n",
        "df_num = df.drop(cat_list, inplace = False , axis = 1) \n",
        "df_cat = df[cat_list]\n",
        "\n",
        "\n",
        "# Cleaning\n",
        "# # (1) Drop irrelevant info: marketplace + product_category + review_id\n",
        "df.drop(['marketplace','product_category','review_id'], axis=1, inplace=True)\n",
        "\n",
        "# (2) Map: vine + verified_purchase (y:1, n:0)\n",
        "YN_to_bool = {'Y': 1,'N': 0}\n",
        "df['vine'] = df['vine'].map( YN_to_bool )\n",
        "df['verified_purchase'] = df['verified_purchase'].map( YN_to_bool)\n",
        "\n",
        "# (3) Datetime: review_date\n",
        "df['review_date'] = pd.to_datetime(df['review_date'])\n",
        "\n",
        "# (4) Create a year column for EDA\n",
        "df['Year'] = df.review_date.dt.year\n",
        " \n",
        "# (5) Combine the review headline and review date columns\n",
        "df['review_body'] = df['review_headline'] + ' ' + df['review_body']\n",
        "del df['review_headline']\n",
        "\n",
        "# (6) Drop the rows where there are no reviews and no review dates\n",
        "df.dropna(subset = ['review_body'], inplace = True)\n",
        "df.dropna(subset = ['review_date'], inplace = True)\n",
        "\n",
        "\n",
        "null_columns=df.columns[df.isnull().any()]\n",
        "df.info()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 299854 entries, 0 to 299999\n",
            "Data columns (total 12 columns):\n",
            " #   Column             Non-Null Count   Dtype         \n",
            "---  ------             --------------   -----         \n",
            " 0   customer_id        299854 non-null  int64         \n",
            " 1   product_id         299854 non-null  object        \n",
            " 2   product_parent     299854 non-null  int64         \n",
            " 3   product_title      299854 non-null  object        \n",
            " 4   star_rating        299854 non-null  int64         \n",
            " 5   helpful_votes      299854 non-null  int64         \n",
            " 6   total_votes        299854 non-null  int64         \n",
            " 7   vine               299854 non-null  int64         \n",
            " 8   verified_purchase  299854 non-null  int64         \n",
            " 9   review_body        299854 non-null  object        \n",
            " 10  review_date        299854 non-null  datetime64[ns]\n",
            " 11  Year               299854 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(1), int64(7), object(3)\n",
            "memory usage: 29.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKVO9FRnB7nz"
      },
      "source": [
        "#### Pre-processing the text fields\n",
        "##### Useful resource for cleaning text\n",
        "https://medium.com/mlearning-ai/10-python-functions-you-need-to-apply-before-you-build-your-nlp-sentiment-analysis-model-874a37e0217e"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kih3Xnvyl9FR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2844d1-ecc8-4e45-8aaa-34c192af87ff"
      },
      "source": [
        "print(df['review_body'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0         ★ THESE REALLY DO WORK GREAT WITH SOME TWEAKIN...\n",
            "1         Favorite for winter. Very warm! I love this dr...\n",
            "2         Great Socks for the money. Nice socks, great c...\n",
            "3         Slick hat! I bought this for my husband and WO...\n",
            "4         I would do it again! Perfect dress and the cus...\n",
            "                                ...                        \n",
            "299995    They would be a decent pair of scrubs for the ...\n",
            "299996    Fit? I want to start by saying I love the styl...\n",
            "299997    One Star They were too small, and it was diffi...\n",
            "299998    For the price these scrubs are great! The top ...\n",
            "299999    Three Stars good quality but it's quite large ...\n",
            "Name: review_body, Length: 299854, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AddOnryNBpPk"
      },
      "source": [
        "# Removing the hashtags | Revise - not working | 2015 mentiones and hashe were'e there? #todo\n",
        "# import re      # Import REGEX\n",
        "# def remove_mentions(text):\n",
        "#   text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
        "#   text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
        "#   return text\n",
        "\n",
        "# df['review_body'] = df.apply(lambda row: remove_mentions(row['review_body']), axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2tNPNqL18Bh"
      },
      "source": [
        "# Removing the emojis |\n",
        "\n",
        "# # Reference code: https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
        "# def remove_emoji(review_body):\n",
        "#     emoji_pattern = re.compile(\"[\"\n",
        "#                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "#                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "#                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "#                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "#                                u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "#                                u\"\\U00002702-\\U000027B0\"\n",
        "#                                u\"\\U00002702-\\U000027B0\"\n",
        "#                                u\"\\U000024C2-\\U0001F251\"\n",
        "#                                u\"\\U0001f926-\\U0001f937\"\n",
        "#                                u\"\\U00010000-\\U0010ffff\"\n",
        "#                                u\"\\u2640-\\u2642\"\n",
        "#                                u\"\\u2600-\\u2B55\"\n",
        "#                                u\"\\u200d\"\n",
        "#                                u\"\\u23cf\"\n",
        "#                                u\"\\u23e9\"\n",
        "#                                u\"\\u231a\"\n",
        "#                                u\"\\ufe0f\"  # dingbats\n",
        "#                                u\"\\u3030\"\n",
        "#                                \"]+\", flags=re.UNICODE)\n",
        "#     return emoji_pattern.sub(r'', string)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goaMsuuiDNON",
        "outputId": "77f03e23-3b1b-4a03-def9-0d793ba7c0a8"
      },
      "source": [
        "# Importing text cleaning libraries \n",
        "# Tokenizer: Tokenization of data. At one stage we will need to deal with our text as a words list to iterate between the words and apply certain functions on it\n",
        "\n",
        "import nltk         #Natural language processing tool-kit\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  # Import Tokenizer.\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R4u4Anv6Piu",
        "outputId": "b9609906-7ec2-4a25-8a6f-0151c2cdf360"
      },
      "source": [
        "# lower all upper case and enumerate words into a list\n",
        "df['review_body'] = df['review_body'].str.lower()\n",
        "# df['review_body'] = df['review_body'].values.tolist()\n",
        "df['review_body']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         ★ these really do work great with some tweakin...\n",
              "1         favorite for winter. very warm! i love this dr...\n",
              "2         great socks for the money. nice socks, great c...\n",
              "3         slick hat! i bought this for my husband and wo...\n",
              "4         i would do it again! perfect dress and the cus...\n",
              "                                ...                        \n",
              "299995    they would be a decent pair of scrubs for the ...\n",
              "299996    fit? i want to start by saying i love the styl...\n",
              "299997    one star they were too small, and it was diffi...\n",
              "299998    for the price these scrubs are great! the top ...\n",
              "299999    three stars good quality but it's quite large ...\n",
              "Name: review_body, Length: 299854, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTFDUv9zWgUf"
      },
      "source": [
        "# Removal of numbers and digits\n",
        "import re      # Import REGEX\n",
        "def remove_numbers(text):\n",
        "  text = re.sub(r'\\d+', '', str(text))\n",
        "  return text\n",
        "\n",
        "df['review_body'] = df.apply(lambda row: remove_numbers(row['review_body']), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57xUt-yzYALg"
      },
      "source": [
        "# Removal of special characters\n",
        "import re, string, unicodedata # Import Regex, string and unicodedata.\n",
        "def remove_non_ascii(words):\n",
        "    words = unicodedata.normalize('NFKD', words).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return words\n",
        "\n",
        "df['review_body'] = df.apply(lambda row: remove_non_ascii(row['review_body']), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2GwxbzuYIN_"
      },
      "source": [
        "# Removal of punctuation\n",
        "import re      # Import REGEX\n",
        "def remove_punctuation(text):\n",
        "  text = re.sub(r'[^\\w\\s]', '', str(text))\n",
        "  return text\n",
        "\n",
        "df['review_body'] = df.apply(lambda row: remove_punctuation(row['review_body']), axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3673tp0ZYZ7Y"
      },
      "source": [
        "# Import nltk stop words\n",
        "# # Removal of stop words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords            #Stopwords corpus\n",
        "stopwords = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn-foBgoYmYo"
      },
      "source": [
        "# Customising the stop words - we need to review this #todo\n",
        "customlist = ['not', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn',\n",
        "        \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\n",
        "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn',\n",
        "        \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "\n",
        "# # Set custom stop-word's list as not, couldn't etc. words matter in Sentiment, so not removing them from original data.\n",
        "\n",
        "stopwords = list(set(stopwords) - set(customlist))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU_47LfyYq06"
      },
      "source": [
        "# after cleaning text, bring the words into a list\n",
        "df['review_body'] = df.apply(lambda row: nltk.word_tokenize(row['review_body']), axis=1)\n",
        "df['review_body']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdqFE7rNpEUc"
      },
      "source": [
        "df.to_csv('./apparelReviewsDataset_300k.csv')\n",
        "print('DF saved as csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlcIQtgryy47"
      },
      "source": [
        "### EDA and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxG5treEPmO"
      },
      "source": [
        "df = pd.read_csv('apparelReviewsDataset_300k.csv')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyzhOFk8zR6v"
      },
      "source": [
        "# Quick check: Using discriptive statistics + measures of dispersion\n",
        "# Note: customer_id and product_parent are random numbers not for descriptive analysis\n",
        "df_discriptive = df.drop(['customer_id', 'product_parent'],axis = 1,inplace = False)\n",
        "df_discriptive.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69ZlPecRzaOc"
      },
      "source": [
        "# Check the distribution of the star rating with the DataFrame | reference chart: https://www.datacamp.com/community/tutorials/histograms-matplotlib\n",
        "# plt.hist(df.star_rating, bins='auto', color = \"skyblue\", ec='grey')\n",
        "# plt.gca().set(title='Frequency Histogram | Review Stars |', ylabel='Frequency',xlabel = 'stars',alpha=0.7, rwidth=0.85);\n",
        "# plt.show()\n",
        "\n",
        "fig = plt.figure(figsize = (12,8))\n",
        "ax = fig.gca()\n",
        "df_discriptive.hist(ax=ax, color = \"skyblue\", ec='grey')\n",
        "plt.show()\n",
        "\n",
        "# Clustering per groups of product parent | votes per product parent\n",
        "# Sentimet (from -ve) most common words for improvement | from (+ve) most common words for gap analysis\n",
        "# we will need to scale our stars to min max\n",
        "# then our scaled stars are our sentiment label, and text is the features? \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qw-EMFLieWSI"
      },
      "source": [
        "# Looking at year and month for review | seems we can extra clean outliers outside 2015 #todo\n",
        "df.star_rating.groupby([df[\"Year\"], df[\"review_date\"].dt.month,df[\"review_date\"].dt.day]).count().plot(kind=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-UGWdMjpBDD"
      },
      "source": [
        "# Looking at product parent | \n",
        "df.product_id.groupby([df[\"product_parent\"],df['star_rating']]).count().plot(kind=\"bar\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhEgJ_k4C5LX"
      },
      "source": [
        "# (4) Choose the label and features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bAuUZonC5LX"
      },
      "source": [
        "# (5) Feature engineer for data that is\n",
        "# (a) relevant \n",
        "# (b) unique\n",
        "# (c) correct \n",
        "# (d) not missing\n",
        "\n",
        "# Drop data that is not a,b,c, or d\n",
        "# Use one-hot encoding for nominal\n",
        "# Reduce dimensions of your features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq6UgamkC5LY"
      },
      "source": [
        "# (6) Confirm data is ready with further exploratory analysis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hoZ8o-kC5LY"
      },
      "source": [
        "# (7) Training, Testing (and/or Validation) data split \n",
        "\n",
        "# for example, 60/20/20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh3Mpqv0C5LY"
      },
      "source": [
        "# (7.b) If using Deep Learning, building the model\n",
        "\n",
        "# Add Input Layer\n",
        "# Add Hidden Layers\n",
        "# Add Output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmY_kfYC5LZ"
      },
      "source": [
        "# (8) Training the Machine Learning Model (i.e, Fitting the Model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZ01SXbIC5LZ"
      },
      "source": [
        "# (9) Evaluate the model metrics for Training (and/or Validation) data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpOxodBC5LZ"
      },
      "source": [
        "# (10) Evaluate the model metris for Testing data\n",
        "\n",
        "\n",
        "# If metrics are poor, optimize either (a) the data, (b) the hyperpamaters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kitVPuJC5LZ"
      },
      "source": [
        "# (11) Use the model for prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WEaNzAVC5La"
      },
      "source": [
        "# (12) Write final predicted data  (e.g, to CSV or JSON, etc.)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}