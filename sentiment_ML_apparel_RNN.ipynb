{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE3w34wvPN5K"
      },
      "source": [
        "# Sentiment Analysis with Recurrent Neural Networks (RNN) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-jDWqqmQO1K"
      },
      "source": [
        "###Terms:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jeiq7wyxP8S3"
      },
      "source": [
        "* Sentiment: ðŸ“‘ Reading a body of text > determine if its positive or negative (1 positive - 0 negative) ; 0.5 factual \n",
        "* NLP : Natural Language Processing \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C5qlL56P9HE"
      },
      "source": [
        "### Import Data and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaBKaaGkM2F0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "import torch\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBmSfP2UQgzN",
        "outputId": "81b5c3aa-8821-4211-f22d-72552b615c7f"
      },
      "source": [
        "df = pd.read_csv('cleaned_apparel_dataset.csv')\n",
        "df_reviews = pd.DataFrame()\n",
        "df_reviews = df[['review_body','star_rating']]\n",
        "df_reviews.rename(columns = {'review_body':'feature','star_rating':'label'},inplace = True)\n",
        "df_reviews.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 49974 entries, 0 to 49973\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   feature  49974 non-null  object\n",
            " 1   label    49974 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 781.0+ KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ku0AxvxftYJM",
        "outputId": "330b6fa8-598b-49fe-baed-e489cb4d4b9e"
      },
      "source": [
        "# Standarize label to 0>1 instead of 1>5\n",
        "df_reviews_normalized = df_reviews.copy()\n",
        "df_reviews_normalized['label'] = (df_reviews_normalized['label'] - df_reviews_normalized['label'].min()) / (df_reviews_normalized['label'].max() - df_reviews_normalized['label'].min())    \n",
        "print(df_reviews_normalized['label'].unique())\n",
        "# print(df_reviews)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75 1.   0.5  0.25 0.  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfsGcTFYQ7ff"
      },
      "source": [
        "# Extract from 'reviewsData' the train and test datasets | they are cleaned \n",
        "# trainData = reviewsData['train']\n",
        "# testData = reviewsData['test']\n",
        "\n",
        "trainData_f, testData_f, trainData_l, testData_l = train_test_split( df_reviews_normalized['feature'], df_reviews_normalized['label'], test_size=0.4, random_state=42)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyiAEWCXxR5G"
      },
      "source": [
        "trainData = pd.DataFrame()\n",
        "trainData = pd.concat([trainData_f, trainData_l], axis=1)\n",
        "# trainData\n",
        "testData = pd.concat([testData_f, testData_l], axis=1)\n",
        "# testData"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOiJ-ocNQ8Jv"
      },
      "source": [
        "# See a glance of the tensor dataset\n",
        "# for feature, label in trainData.take(5):\n",
        "#   print('feature (text):',feature.numpy()) \n",
        "#   print('label (binary):',label.numpy())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAyxFRCySZIL"
      },
      "source": [
        "# bufferSize the maximum number of tokens (words) in any text feature\n",
        "bufferSize = 1000\n",
        "\n",
        "# batchSize is the number of samples to propogate through the network\n",
        "batchSize = 64\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKLMzkEuzba0",
        "outputId": "7b805ac5-aed7-40de-d9b7-c4bcef3411e6"
      },
      "source": [
        "# DF to Tensor Dataset\n",
        "trainDataTs = tf.data.Dataset.from_tensor_slices((trainData['feature'],trainData['label']))\n",
        "testDataTs = tf.data.Dataset.from_tensor_slices((testData['feature'],testData['label']))\n",
        "# testDataTs = tf.data.Dataset.from_tensor_slices((testData))\n",
        "# trainDataTs = tf.convert_to_tensor(trainData)\n",
        "\n",
        "# creating tensor from targets_df \n",
        "# trainDataTs = torch.tensor(trainData)\n",
        "\n",
        "# printing out result\n",
        "print(trainDataTs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmYR0-U51YVF",
        "outputId": "829cf5ea-a4c5-4546-8005-d2e60b068a44"
      },
      "source": [
        "# trainDataTs = trainData['feature']\n",
        "for feature, label in trainDataTs.take(10):\n",
        "  print('feature (text):',feature) \n",
        "  print('label (binary):',label)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature (text): tf.Tensor(b'five stars funny', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'love love love my hat absolutely love love the hat looks exactly like the picture and very good quality im very happy with my purchase', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'sexy beautiful waist cincher and comfortable i ordered a xl  it fit me perfectly and i have noticed that after  weeks of use i have to now move the hooks to the second row first of all i love the pink color on the waist trainer with the black lace over its very sexy in my opinioni have used many different waist trainers so i can honestly say that this one is a pretty good waist trainer i love that the hooks and eyelets are sewn in very well in the past i have had issues with flimsy waist trainers where the hooks fall off this is not the case with this waist trainer it is very comfortable to wear i was able to wear it for hours without discomfort i was very impressed being it is steel boned i also really loved that it doesnt roll up yes i had one that rolled up all the time very annoying which is quite embarrassing i definitely recommend only thing that i dont like is that its not a bit longer but thats just me besides that i love this waist trainer and i will be buying a size smaller pretty soon i received this product at a discount in exchange for my honest review', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(0.75, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'five stars very comfortable and easy to wash', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'five stars excelent', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'five stars great too very goof quality', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'five stars glad to get it', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'five stars absolutely adorable', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'i did not like that it was see through and the top layer  i did not like that it was see through and the top layer did not hang right  i returned it', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(0.25, shape=(), dtype=float64)\n",
            "feature (text): tf.Tensor(b'footsie _ i love this pinksee ladies footies very comfy to wear  the material they used is polyester  cotton made of sheer material this is one size but good thing is this pinksee ladies footies is elastic so even if my sisters are bigger size compare to me still fits to them i mostly wear this with my doll shoes or flat shoesbetter to have this sock than nothing specially your feet sweat a lot dont worry because they are low cut footies so its a no show  as u can see on my photos its not obvious that im wearing a sock actually ive been using this for years already when i was just in college till im working already and still at this moment and even my sisters specially we love flat shoes so i have a collection of footies thats why when i was given a chance to received this pinksee ladies footies for free in exchange of my review i knew that im gonna like it so if your fan of wearing flat shoes like me and looking for a sock that fits and wont show while wearing it then pinksee ladies footies is what i recommend to you ', shape=(), dtype=string)\n",
            "label (binary): tf.Tensor(1.0, shape=(), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXlVHvKNUBl-"
      },
      "source": [
        "# .shuffle() will randomize the dataset\n",
        "# .batch() set the batch size of sampling\n",
        "# .prefetch() will cashe the data while an existing batch is being propagates\n",
        "trainDataTs = trainDataTs.shuffle( buffer_size= bufferSize ).batch(batchSize).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "testDataTs = testDataTs.batch (batchSize).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XtNDx_CiJlk"
      },
      "source": [
        "### Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCPJvnR6iL4Q"
      },
      "source": [
        "# Vocabulary is the total number of unique words in the collection\n",
        "# each review > document\n",
        "# entire reviews > collection\n",
        "\n",
        "vocabSize = 10000 #if we really dum down the texts we can go down to 1000\n",
        "\n",
        "# vector is a list for mathmaticians\n",
        "# Tokenization: splits the words into a vector of tokens ~ words\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens=vocabSize)\n",
        "\n",
        "# Text encoding\n",
        "# Use the .map() method extract only the features (reviews) and exclude the label (sentiment)\n",
        "featureTokens = trainDataTs.map(lambda feature,label: feature)\n",
        "trainDataTs\n",
        "encoder.adapt(featureTokens)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x90oeclsmM_F",
        "outputId": "ac16a3c1-932a-4cd4-ea4f-17df3ed1c4d8"
      },
      "source": [
        "# Preview some of the terms before encoding\n",
        "feature.numpy()[0:50]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'footsie _ i love this pinksee ladies footies very '"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPoDRw-xmFsB",
        "outputId": "bba1aa34-1eb9-4672-d099-84f7d716b25a"
      },
      "source": [
        "# Preview some of the terms after encoding\n",
        "encoder(feature)[0:50].numpy()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   1,    3,   21,    9, 3918,  847, 3353,   16,  220,    8,   43,\n",
              "          2,   55,   36,  377,    7,  661,  265,   75,   14,  509,   55,\n",
              "          9,    7,   44,   24,   13,   41,  261,    7,    9, 3918,  847,\n",
              "       3353,    7,  459,   22,   97,   65,   11, 1995,   29,  233,   24,\n",
              "       2052,    8,   50,  122,   45,    8])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T25gbyDVkqac",
        "outputId": "48a0f18d-f79f-4c98-a727-d06dca6ae69d"
      },
      "source": [
        "# Extract the vocabulay as Numpy array\n",
        "# and preview of the vocabulary words\n",
        "vocab = np.array(encoder.get_vocabulary()) # get distinct vocab used in the whole collection\n",
        "vocab[0:100]\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '[UNK]', 'the', 'i', 'and', 'a', 'it', 'is', 'to', 'this',\n",
              "       'for', 'my', 'in', 'but', 'of', 'was', 'very', 'not', 'stars',\n",
              "       'great', 'on', 'love', 'so', 'fit', 'size', 'with', 'that', 'like',\n",
              "       'as', 'are', 'dress', 'you', 'its', 'small', 'five', 'have',\n",
              "       'they', 'be', 'too', 'shirt', 'nice', 'good', 'just', 'wear',\n",
              "       'one', 'fits', 'quality', 'would', 'at', 'perfect', 'me', 'these',\n",
              "       'well', 'cute', 'really', 'material', 'im', 'or', 'ordered',\n",
              "       'will', 'little', 'than', 'up', 'all', 'comfortable', 'if', 'them',\n",
              "       'am', 'more', 'top', 'product', 'br', 'looks', 'an', 'large',\n",
              "       'made', 'from', 'color', 'can', 'when', 'got', 'out', 'price',\n",
              "       'what', 'because', 'look', 'get', 'had', 'way', 'expected',\n",
              "       'fabric', 'beautiful', 'received', 'no', 'buy', 'your', 'soft',\n",
              "       'even', 'review', 'dont'], dtype='<U67')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wnHxnJVnY63"
      },
      "source": [
        "### Building the Deep Learning Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf4n9h-xk6Jq"
      },
      "source": [
        "modelRNN = tf.keras.Sequential()\n",
        "\n",
        "# Add Encoder Layer\n",
        "modelRNN.add( encoder )\n",
        "\n",
        "# Add Embedding Layer\n",
        "modelRNN.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=len(encoder.get_vocabulary()),\n",
        "        output_dim=64,\n",
        "        mask_zero=True\n",
        "    )   \n",
        ")\n",
        "\n",
        "# Add Bidirectional Layer\n",
        "modelRNN.add(\n",
        "  tf.keras.layers.Bidirectional(\n",
        "      tf.keras.layers.LSTM(64)\n",
        "  )\n",
        ")\n",
        "\n",
        "# Add Dense Layer\n",
        "modelRNN.add(\n",
        "  tf.keras.layers.Dense(64, activation='relu')   \n",
        ")\n",
        "\n",
        "# Add Output Layer\n",
        "modelRNN.add(\n",
        "  tf.keras.layers.Dense(1)   \n",
        ")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDFasnCkpAg8"
      },
      "source": [
        "# Compile the model\n",
        "modelRNN.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfvtqfQconQ4",
        "outputId": "76ac9918-74b5-4ca7-eb38-ee89c65617e4"
      },
      "source": [
        "# Fit the model (i.e, train the model)\n",
        "modelRNN.fit(trainDataTs,epochs = 1)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 271s 559ms/step - loss: 0.4975 - accuracy: 0.5952\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6017ba8d10>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R14imRjNqL4G",
        "outputId": "ddfbfe75-0c12-46cf-9485-0779057d1890"
      },
      "source": [
        "loss_test,accuracy_test = modelRNN.evaluate(testDataTs)\n",
        "\n",
        "print('Loss',loss_test)\n",
        "print('Accuracy',accuracy_test)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 39s 124ms/step - loss: 0.4011 - accuracy: 0.6278\n",
            "Loss 0.40110692381858826\n",
            "Accuracy 0.6278139352798462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pBEZyRMq0SI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d06562-dd4f-44d9-aeaa-666df1071da4"
      },
      "source": [
        "sampleProductReviews = [\n",
        "  \"five stars\",\n",
        "  \"amazing\",\n",
        "  \"material bad\",\n",
        "  \"terrible material\",\n",
        "  'nice',\n",
        "  'small not fit',\n",
        "  'bad fit',\n",
        "  'quality is cheap',\n",
        "  'elegant color',\n",
        "  'great color but bad fit',\n",
        "  ''\n",
        "]\n",
        "predictedSentiments = modelRNN.predict(np.array(sampleProductReviews))\n",
        "\n",
        "print(predictedSentiments)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.7943953 ]\n",
            " [0.576152  ]\n",
            " [0.16299278]\n",
            " [0.02766614]\n",
            " [0.29601392]\n",
            " [0.05155784]\n",
            " [0.17299405]\n",
            " [0.2531648 ]\n",
            " [0.590955  ]\n",
            " [0.38287416]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgxjjyDlGfh-"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}